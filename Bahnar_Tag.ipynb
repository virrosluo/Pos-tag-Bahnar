{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-24T08:27:00.759381Z",
          "iopub.status.busy": "2023-05-24T08:27:00.758629Z",
          "iopub.status.idle": "2023-05-24T08:27:22.037943Z",
          "shell.execute_reply": "2023-05-24T08:27:22.036752Z",
          "shell.execute_reply.started": "2023-05-24T08:27:00.759339Z"
        },
        "trusted": true,
        "id": "n023dDNt2doh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import pandas as pd"
      ],
      "id": "n023dDNt2doh"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAkvRXBW2eqW",
        "outputId": "ab62937f-403f-4a4c-df02-4f5486e2fe8e"
      },
      "id": "HAkvRXBW2eqW",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-24T08:27:46.298564Z",
          "iopub.status.busy": "2023-05-24T08:27:46.297917Z",
          "iopub.status.idle": "2023-05-24T08:27:46.303920Z",
          "shell.execute_reply": "2023-05-24T08:27:46.302744Z",
          "shell.execute_reply.started": "2023-05-24T08:27:46.298523Z"
        },
        "trusted": true,
        "id": "gg9ZlXxo2dok"
      },
      "outputs": [],
      "source": [
        "gpu = torch.device('cuda')\n",
        "cpu = torch.device('cpu')\n",
        "\n",
        "word_to_ix = {}\n",
        "tag_to_ix = {}\n",
        "ix_to_tag = {}"
      ],
      "id": "gg9ZlXxo2dok"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-24T08:27:47.437823Z",
          "iopub.status.busy": "2023-05-24T08:27:47.437430Z",
          "iopub.status.idle": "2023-05-24T08:27:47.442893Z",
          "shell.execute_reply": "2023-05-24T08:27:47.441713Z",
          "shell.execute_reply.started": "2023-05-24T08:27:47.437787Z"
        },
        "trusted": true,
        "id": "7pbKtzDg2dok"
      },
      "outputs": [],
      "source": [
        "START_TAG = \"<START>\"\n",
        "STOP_TAG = \"<STOP>\"\n",
        "EMBEDDING_DIM = 20\n",
        "HIDDEN_DIM = 20"
      ],
      "id": "7pbKtzDg2dok"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Customize"
      ],
      "metadata": {
        "id": "ftVKCua7zo2b"
      },
      "id": "ftVKCua7zo2b"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-24T08:27:48.205369Z",
          "iopub.status.busy": "2023-05-24T08:27:48.204608Z",
          "iopub.status.idle": "2023-05-24T08:27:48.210584Z",
          "shell.execute_reply": "2023-05-24T08:27:48.209441Z",
          "shell.execute_reply.started": "2023-05-24T08:27:48.205329Z"
        },
        "trusted": true,
        "id": "Iw1S5oa82dol"
      },
      "outputs": [],
      "source": [
        "def argmax(vector):\n",
        "    _, idx = torch.max(vector, 1)\n",
        "    return idx.item()"
      ],
      "id": "Iw1S5oa82dol"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-24T08:27:48.792172Z",
          "iopub.status.busy": "2023-05-24T08:27:48.791737Z",
          "iopub.status.idle": "2023-05-24T08:27:48.798224Z",
          "shell.execute_reply": "2023-05-24T08:27:48.796632Z",
          "shell.execute_reply.started": "2023-05-24T08:27:48.792137Z"
        },
        "trusted": true,
        "id": "lgimtDwV2dol"
      },
      "outputs": [],
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype = torch.long)"
      ],
      "id": "lgimtDwV2dol"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-24T08:27:49.597554Z",
          "iopub.status.busy": "2023-05-24T08:27:49.596766Z",
          "iopub.status.idle": "2023-05-24T08:27:49.605498Z",
          "shell.execute_reply": "2023-05-24T08:27:49.604067Z",
          "shell.execute_reply.started": "2023-05-24T08:27:49.597512Z"
        },
        "trusted": true,
        "id": "H9Bof3JU2dom"
      },
      "outputs": [],
      "source": [
        "# @vec: in GPU environment\n",
        "# @outputs: in GPU environment\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "\n",
        "    max_score_boardcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "\n",
        "    exp = torch.exp(vec - max_score_boardcast)\n",
        "\n",
        "    sum = torch.sum(exp)\n",
        "\n",
        "    log = torch.log(sum)\n",
        "\n",
        "    outputs = max_score + log\n",
        "\n",
        "    return outputs"
      ],
      "id": "H9Bof3JU2dom"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-24T09:17:00.452044Z",
          "iopub.status.busy": "2023-05-24T09:17:00.451601Z",
          "iopub.status.idle": "2023-05-24T09:17:00.487251Z",
          "shell.execute_reply": "2023-05-24T09:17:00.485881Z",
          "shell.execute_reply.started": "2023-05-24T09:17:00.452008Z"
        },
        "trusted": true,
        "id": "qhKfTlv-2dom"
      },
      "outputs": [],
      "source": [
        "class BiLSTM_CRF(nn.Module):\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim).to(gpu)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers = 1, bidirectional = True).to(gpu)\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size).to(gpu)\n",
        "\n",
        "        transition_temp = nn.Parameter(torch.randn(self.tagset_size, self.tagset_size))\n",
        "        transition_temp.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        transition_temp.data[:, tag_to_ix[STOP_TAG]] = - 10000\n",
        "        self.transition = transition_temp.to(gpu)\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        h = torch.randn(2, 1, self.hidden_dim)\n",
        "        c = torch.randn(2, 1, self.hidden_dim)\n",
        "\n",
        "        return (h.to(gpu), c.to(gpu))\n",
        "    \n",
        "    # @sentence: in GPU\n",
        "    # lstm_feats: in GPU\n",
        "    def lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence)\n",
        "        embeds = embeds.reshape(len(sentence), 1, -1)\n",
        "\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "\n",
        "        lstm_forward = lstm_out[:, :, : self.hidden_dim]\n",
        "        lstm_backward = lstm_out[:, :, self.hidden_dim : ]\n",
        "\n",
        "        combine = torch.cat([lstm_forward.unsqueeze(0), lstm_backward.unsqueeze(0)], \n",
        "                            dim = 0)\n",
        "        lstm_out = torch.mean(combine, dim = 0)\n",
        "\n",
        "        lstm_out = lstm_out.reshape((lstm_out.shape[0], self.hidden_dim))\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "\n",
        "        return lstm_feats\n",
        "    \n",
        "    # @feats: in CPU\n",
        "    # @tags: in CPU\n",
        "    def score_sentence(self, feats, tags):\n",
        "        score = torch.zeros(1)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype= torch.long), tags])\n",
        "\n",
        "        transition_cpu = self.transition.to(cpu)\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + transition_cpu[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "\n",
        "        score = score + transition_cpu[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "        \n",
        "    # @feats: in GPU because we do not use this very much\n",
        "    # @return_value: in CPU\n",
        "    def viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(gpu)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                next_tag_var = forward_var + self.transition[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transition[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score.to(cpu), best_path\n",
        "\n",
        "    # The parameters is in GPU\n",
        "    # @feats: (num_word, num_tag)\n",
        "    def all_case_score(self, feats):\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000).to(gpu)\n",
        "\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        for feat in feats:\n",
        "            alphas_t = []\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                emit_score = feat[next_tag].reshape(1, -1).expand(1, self.tagset_size)\n",
        "\n",
        "                trans_score = self.transition[next_tag].view(1, -1)\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).reshape(1))\n",
        "\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transition[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "                \n",
        "    # @sentence: in CPU\n",
        "    # @tags: in CPU\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self.lstm_features(sentence.to(gpu))\n",
        "        feats_cpu = feats.to(cpu)\n",
        "\n",
        "        forward_score = self.all_case_score(feats).to(cpu)\n",
        "        gold_score = self.score_sentence(feats_cpu, tags)\n",
        "\n",
        "        return forward_score - gold_score\n",
        "    \n",
        "    def forward(self, sentence):\n",
        "        lstm_feats = self.lstm_features(sentence.to(gpu))\n",
        "\n",
        "        score, tag_seq = self.viterbi_decode(lstm_feats)\n",
        "\n",
        "        return score, tag_seq"
      ],
      "id": "qhKfTlv-2dom"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read training set and test set"
      ],
      "metadata": {
        "id": "1dM7W8V_1vwb"
      },
      "id": "1dM7W8V_1vwb"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "22eaefb9",
      "metadata": {
        "id": "22eaefb9"
      },
      "outputs": [],
      "source": [
        "# seq_list: A list of list tokens\n",
        "# tag_list: A list of list tags\n",
        "def read_data(filename):\n",
        "    csv_reader = pd.read_excel(filename, header=1)\n",
        "    \n",
        "    seqs = []\n",
        "    tags = []\n",
        "\n",
        "    for _,row in csv_reader.iterrows():\n",
        "        seqs.append(row[0].split(','))\n",
        "        tags.append(row[1].split(','))\n",
        "\n",
        "    return (seqs, tags)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_data(filename):\n",
        "    seq_list, tag_list = read_data(filename)\n",
        "    \n",
        "    training_data = []\n",
        "    for words, tag in zip(seq_list, tag_list):\n",
        "      \n",
        "        if(len(words) != len(tag)):\n",
        "            continue\n",
        "        training_data.append((words, tag))\n",
        "\n",
        "    return training_data"
      ],
      "metadata": {
        "id": "-Q_QiKZRz5am"
      },
      "id": "-Q_QiKZRz5am",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_data(filename):\n",
        "    seq_list, tag_list = read_data(filename)\n",
        "    testing_data = []\n",
        "\n",
        "    for seqs, tags in zip(seq_list, tag_list):\n",
        "        word_verify = [x in word_to_ix for x in seqs]\n",
        "        tag_verify = [x in tag_to_ix for x in tags]\n",
        "\n",
        "        if all(word_verify) and all(tag_verify):\n",
        "            testing_data.append((seqs, tags))\n",
        "\n",
        "    print(len(testing_data))\n",
        "    return testing_data"
      ],
      "metadata": {
        "id": "Q9ZEhGPvzym0"
      },
      "id": "Q9ZEhGPvzym0",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-24T09:28:12.076131Z",
          "iopub.status.busy": "2023-05-24T09:28:12.075376Z",
          "iopub.status.idle": "2023-05-24T09:28:12.109993Z",
          "shell.execute_reply": "2023-05-24T09:28:12.108881Z",
          "shell.execute_reply.started": "2023-05-24T09:28:12.076089Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ju2XdHs2dop",
        "outputId": "70ebf3fd-bc49-43b3-d4bd-40a84d3ddafe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentence: 100\n"
          ]
        }
      ],
      "source": [
        "training_data = train_data('/content/drive/MyDrive/Dataset/Training_Bahnar/Training_set.xlsx')\n",
        "\n",
        "# Split only 20 sentence for test training data\n",
        "# training_data = training_data[:20]\n",
        "\n",
        "for sentence, tags in training_data:\n",
        "    for word, tag in zip(sentence, tags):\n",
        "\n",
        "        if word not in word_to_ix:\n",
        "            # Function: WORD -> INDEX\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "        \n",
        "        if tag not in tag_to_ix:\n",
        "            # Function TAG -> INDEX\n",
        "            tag_to_ix[tag] = len(tag_to_ix)\n",
        "\n",
        "            # Function INDEX -> TAG\n",
        "            ix_to_tag[len(tag_to_ix) - 1] = tag\n",
        "\n",
        "tag_to_ix['<START>'] = len(tag_to_ix)\n",
        "tag_to_ix['<STOP>'] = len(tag_to_ix)\n",
        "\n",
        "print(f\"Number of sentence: {len(training_data)}\")"
      ],
      "id": "7Ju2XdHs2dop"
    },
    {
      "cell_type": "code",
      "source": [
        "print(training_data[0][0])\n",
        "print(training_data[0][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Wtw_g-Pd7xq",
        "outputId": "141c4800-c98a-4adf-fb1b-d66128863bf5"
      },
      "id": "6Wtw_g-Pd7xq",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['đôi', 'bĭ', 'alê̆', 'đơ̆i', 'năr', 'lơnga', 'lu bơ̆n', 'jơh', 'lêch', 'sơnglŏng']\n",
            "['N', 'R', 'V', 'R', 'N', 'V', 'P', 'R', 'V', 'N']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Section"
      ],
      "metadata": {
        "id": "q8XYCYx612EZ"
      },
      "id": "q8XYCYx612EZ"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-24T09:28:34.498514Z",
          "iopub.status.busy": "2023-05-24T09:28:34.497763Z",
          "iopub.status.idle": "2023-05-24T09:28:34.508850Z",
          "shell.execute_reply": "2023-05-24T09:28:34.507783Z",
          "shell.execute_reply.started": "2023-05-24T09:28:34.498474Z"
        },
        "trusted": true,
        "id": "c2WIVAe02doq"
      },
      "outputs": [],
      "source": [
        "model = BiLSTM_CRF(len(word_to_ix), tag_to_ix, EMBEDDING_DIM, HIDDEN_DIM)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, weight_decay= 1e-4)"
      ],
      "id": "c2WIVAe02doq"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-24T09:28:35.634538Z",
          "iopub.status.busy": "2023-05-24T09:28:35.633611Z",
          "iopub.status.idle": "2023-05-24T09:28:35.652011Z",
          "shell.execute_reply": "2023-05-24T09:28:35.650975Z",
          "shell.execute_reply.started": "2023-05-24T09:28:35.634487Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bh8yv2Pl2doq",
        "outputId": "6787e417-8b84-45c4-e85f-1b85a3580b61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(27.0021)\n",
            "Predict tag:\t ['F', 'X', 'QUESTION', 'Np', 'N', 'QUESTION', 'Np', 'N', 'V', 'A']\n",
            "True tag:\t ['N', 'R', 'V', 'R', 'N', 'V', 'P', 'R', 'V', 'N']\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    precheck_sent = prepare_sequence(training_data[0][0], word_to_ix)\n",
        "    precheck_tags = training_data[0][1]\n",
        "\n",
        "    score, predict_tags = model(precheck_sent.to(gpu))\n",
        "\n",
        "    print(score)\n",
        "    print('Predict tag:\\t', [ix_to_tag[tag] for tag in predict_tags])\n",
        "    print(\"True tag:\\t\", precheck_tags)"
      ],
      "id": "bh8yv2Pl2doq"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-05-24T09:28:36.847732Z",
          "iopub.status.busy": "2023-05-24T09:28:36.846589Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9LmWxdF2dor",
        "outputId": "1b3b2a79-56bd-4b89-bea9-f99ab496573f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "End epoch 0 with loss 7258.371290206909\n",
            "End epoch 1 with loss 6085.455087661743\n",
            "End epoch 2 with loss 5336.983615875244\n",
            "End epoch 3 with loss 4661.423761367798\n",
            "End epoch 4 with loss 4054.0585193634033\n",
            "End epoch 5 with loss 3523.1279430389404\n",
            "End epoch 6 with loss 3069.406349182129\n",
            "End epoch 7 with loss 2709.944366455078\n",
            "End epoch 8 with loss 2400.266975402832\n",
            "End epoch 9 with loss 2153.0834922790527\n",
            "End epoch 10 with loss 1932.2214584350586\n",
            "End epoch 11 with loss 1761.8711280822754\n",
            "End epoch 12 with loss 1602.4198112487793\n",
            "End epoch 13 with loss 1466.6021614074707\n",
            "End epoch 14 with loss 1328.7052383422852\n",
            "End epoch 15 with loss 1216.3342247009277\n",
            "End epoch 16 with loss 1122.8028373718262\n",
            "End epoch 17 with loss 1038.800765991211\n",
            "End epoch 18 with loss 950.663501739502\n",
            "End epoch 19 with loss 900.2775993347168\n",
            "End epoch 20 with loss 807.7732315063477\n",
            "End epoch 21 with loss 763.1480331420898\n",
            "End epoch 22 with loss 698.6418228149414\n",
            "End epoch 23 with loss 658.9648361206055\n",
            "End epoch 24 with loss 603.3756370544434\n",
            "End epoch 25 with loss 554.6781997680664\n",
            "End epoch 26 with loss 523.1018753051758\n",
            "End epoch 27 with loss 488.9426574707031\n",
            "End epoch 28 with loss 456.3275909423828\n",
            "End epoch 29 with loss 420.440616607666\n",
            "End epoch 30 with loss 422.95520401000977\n",
            "End epoch 31 with loss 370.3581771850586\n",
            "End epoch 32 with loss 355.3666191101074\n",
            "End epoch 33 with loss 344.60265350341797\n",
            "End epoch 34 with loss 319.5378761291504\n",
            "End epoch 35 with loss 296.23726654052734\n",
            "End epoch 36 with loss 288.282039642334\n",
            "End epoch 37 with loss 263.5237693786621\n",
            "End epoch 38 with loss 260.24068450927734\n",
            "End epoch 39 with loss 257.59081649780273\n",
            "End epoch 40 with loss 241.19451522827148\n",
            "End epoch 41 with loss 229.79112243652344\n",
            "End epoch 42 with loss 225.84613418579102\n",
            "End epoch 43 with loss 202.26485061645508\n",
            "End epoch 44 with loss 185.86816787719727\n",
            "End epoch 45 with loss 192.89437103271484\n",
            "End epoch 46 with loss 171.59555435180664\n",
            "End epoch 47 with loss 171.54494857788086\n",
            "End epoch 48 with loss 169.76312637329102\n",
            "End epoch 49 with loss 157.91997146606445\n",
            "End epoch 50 with loss 148.9512710571289\n",
            "End epoch 51 with loss 146.45875549316406\n",
            "End epoch 52 with loss 140.69223403930664\n",
            "End epoch 53 with loss 139.08145904541016\n",
            "End epoch 54 with loss 134.25243377685547\n",
            "End epoch 55 with loss 129.4119415283203\n",
            "End epoch 56 with loss 134.90567016601562\n",
            "End epoch 57 with loss 120.18840408325195\n",
            "End epoch 58 with loss 118.8048324584961\n",
            "End epoch 59 with loss 117.51452255249023\n",
            "End epoch 60 with loss 111.22086715698242\n",
            "End epoch 61 with loss 100.2072868347168\n",
            "End epoch 62 with loss 107.24938583374023\n",
            "End epoch 63 with loss 109.03128433227539\n",
            "End epoch 64 with loss 101.30004501342773\n",
            "End epoch 65 with loss 100.4929084777832\n",
            "End epoch 66 with loss 96.2324447631836\n",
            "End epoch 67 with loss 99.91483306884766\n",
            "End epoch 68 with loss 91.17998886108398\n",
            "End epoch 69 with loss 84.05510711669922\n",
            "End epoch 70 with loss 82.18348693847656\n",
            "End epoch 71 with loss 95.68341827392578\n",
            "End epoch 72 with loss 79.68545532226562\n",
            "End epoch 73 with loss 80.92700958251953\n",
            "End epoch 74 with loss 78.67214584350586\n",
            "End epoch 75 with loss 75.26374435424805\n",
            "End epoch 76 with loss 74.63943481445312\n",
            "End epoch 77 with loss 71.57097625732422\n",
            "End epoch 78 with loss 80.84773635864258\n",
            "End epoch 79 with loss 69.7999496459961\n",
            "End epoch 80 with loss 74.13472366333008\n",
            "End epoch 81 with loss 63.741676330566406\n",
            "End epoch 82 with loss 74.11702728271484\n",
            "End epoch 83 with loss 57.107730865478516\n",
            "End epoch 84 with loss 61.67683029174805\n",
            "End epoch 85 with loss 60.31294250488281\n",
            "End epoch 86 with loss 54.94447708129883\n",
            "End epoch 87 with loss 54.68720245361328\n",
            "End epoch 88 with loss 57.30091094970703\n",
            "End epoch 89 with loss 60.85735321044922\n",
            "End epoch 90 with loss 51.2874641418457\n",
            "End epoch 91 with loss 56.11742401123047\n",
            "End epoch 92 with loss 51.339813232421875\n",
            "End epoch 93 with loss 50.498809814453125\n",
            "End epoch 94 with loss 55.077999114990234\n",
            "End epoch 95 with loss 53.33896255493164\n",
            "End epoch 96 with loss 45.02100372314453\n",
            "End epoch 97 with loss 48.60973358154297\n",
            "End epoch 98 with loss 44.874732971191406\n",
            "End epoch 99 with loss 51.187400817871094\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(100):\n",
        "    totalLoss = 0\n",
        "    for sentence, tags in training_data:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        sentence = prepare_sequence(sentence, word_to_ix)\n",
        "        tags = torch.tensor([tag_to_ix[t] for t in tags], dtype=torch.long)\n",
        "\n",
        "        loss = model.neg_log_likelihood(sentence, tags)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            totalLoss +=  loss.item()\n",
        "    print(f\"End epoch {epoch} with loss {totalLoss}\")"
      ],
      "id": "f9LmWxdF2dor"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Section"
      ],
      "metadata": {
        "id": "7p5jIHgD15F1"
      },
      "id": "7p5jIHgD15F1"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-24T07:41:58.663692Z",
          "iopub.status.idle": "2023-05-24T07:41:58.664593Z",
          "shell.execute_reply": "2023-05-24T07:41:58.664326Z",
          "shell.execute_reply.started": "2023-05-24T07:41:58.664292Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNtEJKiO2dor",
        "outputId": "6826c35c-d914-4f03-ad03-c118a06aa5b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "9/10\n",
            "10/10\n",
            "9/10\n",
            "9/10\n",
            "9/11\n",
            "15/15\n",
            "15/15\n",
            "7/7\n",
            "9/9\n",
            "10/10\n",
            "8/10\n",
            "10/10\n",
            "12/14\n",
            "12/14\n",
            "11/11\n",
            "16/16\n",
            "11/11\n",
            "12/13\n",
            "13/16\n",
            "13/16\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "\n",
        "    testing_data = test_data('/content/drive/MyDrive/Dataset/Training_Bahnar/Testing_set.xlsx')\n",
        "\n",
        "    for words, tags in testing_data:\n",
        "      precheck_sent = prepare_sequence(words, word_to_ix)\n",
        "      \n",
        "      predict_tags = model(precheck_sent)[1]\n",
        "\n",
        "      count = 0\n",
        "      for tag, predict_tag in zip(tags, predict_tags):\n",
        "          if(tag_to_ix[tag] == predict_tag):\n",
        "              count += 1\n",
        "\n",
        "      print(f\"{count}/{len(tags)}\")\n",
        "\n",
        "      # break"
      ],
      "id": "fNtEJKiO2dor"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving Model"
      ],
      "metadata": {
        "id": "vARf_cO118za"
      },
      "id": "vARf_cO118za"
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model\n",
        "torch.save(model, 'model_complete.pth')"
      ],
      "metadata": {
        "id": "gUOLka9RncSo"
      },
      "id": "gUOLka9RncSo",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9gsKC0IRDTD0"
      },
      "id": "9gsKC0IRDTD0",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}